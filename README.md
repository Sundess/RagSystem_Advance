# ðŸ“– RagSystem

RagSystem is a **Retrieval-Augmented Generation (RAG)** application that lets you upload documents, process them into embeddings and store them in pineocne vector database, and interact with them through **Gemini AI** for context-aware Q\&A.

---

## ðŸ“‚ Folder Structure

```
RagSystem/
â”œâ”€â”€ main.py                    # Main entry point
â”œâ”€â”€ utils/                     # Utility modules
â”‚   â”œâ”€â”€ __init__.py            # Package initialization
â”‚   â”œâ”€â”€ pinecone_manager.py    # Pinecone vector DB operations
â”‚   â”œâ”€â”€ gemini_chat.py         # Gemini AI integration
â”‚   â””â”€â”€ file_processor.py      # File handling (TXT, PDF, DOCX, MD)
â”œâ”€â”€ data/                      # Documents folder
â”œâ”€â”€ .env                       # Environment variables (API keys)
â”œâ”€â”€ .env.example               # Template for environment setup
â””â”€â”€ requirements.txt           # Project dependencies
```

---

## ðŸš€ Features

* **File Processing**: Automatically handles `.txt`, `.pdf`, `.docx`, and `.md`
* **Pinecone Integration**: Vector storage + retrieval with status monitoring
* **Gemini AI**: Contextual, accurate answers to your queries
* **Interactive Chat**: Ask follow-up questions in a continuous conversation
* **Modular Design**: Clean, extensible, and easy-to-maintain codebase

---

## ðŸ”§ Supported File Types

* `.txt` â†’ Plain text
* `.pdf` â†’ PDF documents
* `.docx` / `.doc` â†’ Word files
* `.md` â†’ Markdown files

The system **auto-detects file type** and processes it seamlessly. Upload documents, chat with Gemini, and get precise, context-driven answers instantly.

Do you also want me to add a **Quick Start section with setup and usage commands** (like `pip install -r requirements.txt` and `python main.py`)? That would make the README even more practical.
